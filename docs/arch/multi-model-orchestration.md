# 多模型协同架构 (Multi-Model Orchestration)

本专题探讨 OpenCode 如何通过多模型协同设计（Multi-Model Orchestration）实现复杂任务的拆解、性能优化与成本控制。

---

## 1. 核心范式：策略路由与职责分离

在 OpenCode 中，并不是所有任务都由同一个“全能”模型处理。系统采用了**多层级代理路由（Multi-Tier Agent Routing）**的架构，根据任务的复杂度和实时性要求，将工作分配给最合适的模型。

### 核心角色与职责

- **主代理 (Primary Agents - "总承包商")**：
    - **代表**：`Build`, `Plan`
    - **职责**：处理高层意图理解、全局规划、复杂代码生成与逻辑推理。
    - **模型选择**：通常绑定顶级 LLM（如 Claude 3.5 Sonnet, GPT-4o），以确保逻辑的严密性。
- **子代理 (Subagents - "专业工兵")**：
    - **代表**：`General`, `Explore`
    - **职责**：执行特定领域的繁重任务，如全文搜索、代码库扫描、文档研究。
    - **模型选择**：常选用响应速度快、成本低的“中量级”模型（如 Claude Haiku, Gemini Flash）。
- **实用型小模型 (Utility Models - "轻骑兵")**：
    - **配置项**：`small_model`
    - **职责**：处理标题生成、对话总结 (Compaction)、简单的文本转换等低逻辑要求任务。
    - **价值**：实现秒级交互，极大降低 Token 消耗。

---

## 2. 架构机制：精细化的任务派发

### 2.1 声明式模型绑定
用户可以通过 `opencode.json` 对每个 Agent 进行独立的模型配置。这种设计实现了**能力与执行器的解耦**。

```json
{
  "model": "anthropic/claude-3-5-sonnet", // 全局默认模型
  "small_model": "anthropic/claude-3-haiku", // 轻量任务专用
  "agent": {
    "explore": {
      "model": "google/gemini-1.5-flash", // 针对大规模上下文搜索优化
      "mode": "subagent"
    }
  }
}
```

### 2.2 动态提示词路由 (Dynamic Prompt Routing)
系统会根据当前执行任务的模型 ID，自动映射并注入最适合该模型的提示词模版（如 `anthropic.txt`, `gemini.txt`, `beast.txt`）。这确保了每种模型都能在其最擅长的格式偏好（XML vs Markdown）下运行。

---

## 3. 可迁移的设计思想

### “重武器”与“轻骑兵”的辩证法
在构建 AI 系统时，不要试图用一个最贵的模型解决所有问题。
- **复杂推理（核心逻辑）**：使用 SOTA 模型，不计成本追求准确度。
- **简单处理（格式化、搜索）**：使用小模型，追求极速响应与性价比。

### 配置化而非硬编码
将模型选择权交给配置层。这种“声明式”设计让系统具备了极强的**前瞻性**——当行业内出现性价比更高的新模型时，只需修改一行配置即可完成平滑迁移，而无需重写业务逻辑。

---

## 4. 生产级考量：性能与成本的平衡

- **响应延迟 (Latency)**：将 UI 交互相关的轻量任务（如标题生成）分配给小模型，可将延迟从 5-8 秒降低至 1 秒以内。
- **经济性 (Economics)**：在典型的开发 Session 中，子代理和总结任务占据了大量的 Token 消耗。通过协同架构，整体运营成本可降低 40% - 60%。

---

> **教授箴言**
>
> “一个优秀的架构师不应该追求‘最强的工具’，而应该追求‘最合适的组合’。多模型协同不是简单的堆砌，而是对‘分治法’（Divide and Conquer）的深度演进。它通过将**任务逻辑**与**计算算力**解耦，实现了系统柔性与效能的统一。”
